{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 0
   },
   "source": [
    "# Classification Metrics Review\n",
    "\n",
    "Below we import a dataset containing information about customers who are currently paying for Health Insurance. The `Response` variable indicates whether or not the customer is interested in paying for Vehicle Insurance, where `1` means \"interested\" and `0` means \"not interested.\n",
    "\n",
    "For more about this dataset, you can review the documentation [here](https://www.kaggle.com/arashnic/imbalanced-data-practice?select=aug_train.csv)\n",
    "\n",
    "**Below we import the insurance dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/aug_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 2
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/aug_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 3
   },
   "source": [
    "## Task 1 \n",
    "### Seperate the features from the target.\n",
    "* Assign the features to `X`.\n",
    "* Assign the target to `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 4
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 5
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "X = df.drop('Response', axis = 1)\n",
    "y = df.Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 6
   },
   "source": [
    "## Task 2 \n",
    "### Drop the `id` column from `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 7
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 8
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "X = X.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 9
   },
   "source": [
    "## Task 3 \n",
    "### Create a train test split\n",
    "> Set the random state to `2021`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 10
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 11
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 12
   },
   "source": [
    "## Task 4\n",
    "### Select the numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 13
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 14
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "X_train_numeric = X_train.select_dtypes('number')\n",
    "X_test_numeric = X_test[X_train_numeric.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 15
   },
   "source": [
    "## Task 5 \n",
    "### Import a scaler and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 16
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 17
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_numeric)\n",
    "X_train_scaled = scaler.transform(X_train_numeric)\n",
    "X_test_scaled = scaler.transform(X_test_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 18
   },
   "source": [
    "## Task 6 \n",
    "### Initialize a logistic regression model\n",
    "* Set the random state to `2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 19
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 20
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 21
   },
   "source": [
    "## Task 7 \n",
    "### Fit the model to the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 22
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 23
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 24
   },
   "source": [
    "## Task 8 \n",
    "### Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 25
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 26
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 27
   },
   "source": [
    "## Task 9 \n",
    "### Please calculate the accuracy score for the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 28
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "print('{:.2}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 29
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_9\n",
    "question_9.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 30
   },
   "source": [
    "## Task 10 \n",
    "### Please calculate the precision score for the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 31
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.metrics import precision_score\n",
    "score = precision_score(y_train, model.predict(X_train_scaled))\n",
    "print('{:.2}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 32
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_10\n",
    "question_10.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 33
   },
   "source": [
    "## Task 11 \n",
    "### Please calculate the recall score for the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 34
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.metrics import recall_score\n",
    "score = recall_score(y_train, model.predict(X_train_scaled))\n",
    "print('{:.2}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 35
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_11\n",
    "question_11.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 36
   },
   "source": [
    "## Task 12 \n",
    "### Please calculate the f1 score for the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 37
   },
   "outputs": [],
   "source": [
    "#==SOLUTION== \n",
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(y_train, model.predict(X_train_scaled))\n",
    "print('{:.2}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 38
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_12\n",
    "question_12.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 39
   },
   "source": [
    "## Task 13 \n",
    "### Multiple Choice\n",
    "\n",
    "We are working on a modeling project, and have determined that false positives are the most costly outcome. An ideal metric for this project is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 40
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_13\n",
    "question_13.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 41
   },
   "source": [
    "## Task 14 \n",
    "### Multiple Choice\n",
    "\n",
    "We are working on a modeling project, and have determined that **false negatives are the most costly outcome**. An ideal metric for this project is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 42
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_14\n",
    "question_14.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 43
   },
   "source": [
    "## Task 15 \n",
    "### Multiple Choice\n",
    "We are working on a modeling project with **imbalanced data**, and **we do not have a strong preference between false positives and false negatives**. An ideal metric for this project is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 44
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_15\n",
    "question_15.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 45
   },
   "source": [
    "## Task 16 \n",
    "### Multiple Choice\n",
    "\n",
    "We are working on a modeling project with **balanced data**, and **we do not have a strong preference between false positives and false negatives**. An ideal metric for this project is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 46
   },
   "outputs": [],
   "source": [
    "# Run this cell unchanged\n",
    "from src.questions import question_16\n",
    "question_16.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
