{"cells": [{"cell_type": "markdown", "metadata": {"index": 0}, "source": ["# Classification Metrics Review\n", "\n", "Below we import a dataset containing information about customers who are currently paying for Health Insurance. The `Response` variable indicates whether or not the customer is interested in paying for Vehicle Insurance, where `1` means \"interested\" and `0` means \"not interested.\n", "\n", "For more about this dataset, you can review the documentation [here](https://www.kaggle.com/arashnic/imbalanced-data-practice?select=aug_train.csv)\n", "\n", "**Below we import the insurance dataset.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 1}, "outputs": [], "source": ["import pandas as pd\n", "df = pd.read_csv('data/aug_train.csv')\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {"index": 3}, "source": ["## Task 1 \n", "### Seperate the features from the target.\n", "* Assign the features to `X`.\n", "* Assign the target to `y`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 4}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 6}, "source": ["## Task 2 \n", "### Drop the `id` column from `X`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 7}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 9}, "source": ["## Task 3\n", "### Why did we drop the `id` column before fitting a model?"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["*YOUR ANSWER HERE*"]}, {"cell_type": "markdown", "metadata": {"index": 11}, "source": ["## Task 4 \n", "### Create a train test split\n", "> Set the random state to `2021`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 12}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 14}, "source": ["## Task 5 \n", "### Select the numeric features"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 15}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 17}, "source": ["## Task 6 \n", "### Import a scaler and scale the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 18}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 20}, "source": ["## Task 7 \n", "### Initialize a logistic regression model\n", "* Set the random state to `2021`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 21}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 23}, "source": ["## Task 8 \n", "### Fit the model to the scaled data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 24}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 26}, "source": ["## Task 9 \n", "### Plot a confusion matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 27}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {"index": 29}, "source": ["## Task 10 \n", "### Please calculate the accuracy score for the above model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 31}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_9\n", "question_9.display()"]}, {"cell_type": "markdown", "metadata": {"index": 32}, "source": ["## Task 11 \n", "### Please calculate the precision score for the above model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 34}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_10\n", "question_10.display()"]}, {"cell_type": "markdown", "metadata": {"index": 35}, "source": ["## Task 12 \n", "### Please calculate the recall score for the above model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 37}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_11\n", "question_11.display()"]}, {"cell_type": "markdown", "metadata": {"index": 38}, "source": ["## Task 13 \n", "### Please calculate the f1 score for the above model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 40}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_12\n", "question_12.display()"]}, {"cell_type": "markdown", "metadata": {"index": 41}, "source": ["## Task 14 \n", "### Multiple Choice\n", "\n", "We are working on a modeling project, and have determined that false positives are the most costly outcome. An ideal metric for this project is:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 42}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_13\n", "question_13.display()"]}, {"cell_type": "markdown", "metadata": {"index": 43}, "source": ["## Task 15 \n", "### Multiple Choice\n", "\n", "We are working on a modeling project, and have determined that **false negatives are the most costly outcome**. An ideal metric for this project is:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 44}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_14\n", "question_14.display()"]}, {"cell_type": "markdown", "metadata": {"index": 45}, "source": ["## Task 16 \n", "### Multiple Choice\n", "We are working on a modeling project with **imbalanced data**, and **we do not have a strong preference between false positives and false negatives**. An ideal metric for this project is:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 46}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_15\n", "question_15.display()"]}, {"cell_type": "markdown", "metadata": {"index": 47}, "source": ["## Task 17 \n", "### Multiple Choice\n", "\n", "We are working on a modeling project with **balanced data**, and **we do not have a strong preference between false positives and false negatives**. An ideal metric for this project is:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 48}, "outputs": [], "source": ["# Run this cell unchanged\n", "from src.questions import question_16\n", "question_16.display()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}